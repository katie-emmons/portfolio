# portfolio

## 181st Meeting of the Acoustical Society of America (2021)
**Multitalker speech perception in neurodiverse populations.**
Katherine A. Emmons (University of Washington Autism Center, University of Washington, 1701 NE Columbia Rd., Seattle, WA), Annette Estes (Department of Speech and Hearing Sciences, University of Washington, Seattle, WA), Stephen Dager (Department of Radiology, University of Washington, Seattle, WA), Ross K. Maddox (University of Rochester, Rochester, NY),
Susan Astley Hemingway (Center on Human Development and Disability, University of Washington, Seattle, WA), John C. Thorne, Adrian KC Lee (Department of Speech and Hearing Sci., Univ. of Washington, Seattle, WA), and Bonnie K. Lau (Dept. of Otolaryngology-Head and Neck Surgery, University of Washington, Seattle, WA)

The ability to selectively attend to one talker in the presence of competing talkers is a crucial skill employed in everyday life. In this study, multitalker speech perception thresholds were measured in three groups; Autism Spectrum Disorder (ASD), Fetal Alcohol Syndrome Disorder (FASD), and an age- and sex-matched typically functioning (TF) group. Participants listened to three simultaneous sentences from the Coordinate Response Measure corpus: the target stream to be attended (0° azimuth) and two spatially
separated (45° azimuth) masker streams. Participants were asked to identify the color and number associated with the callsign “Charlie.” Target-to-masker ratios (TMRs) were estimated based on the average of four runs in which the target was fixed at 40 dB SPL and maskers were adaptively varied using a one-up-one-down procedure to estimate 50% correct. The target
speaker was always male; the two maskers were either male/male or female/female. Overall, TMR thresholds were higher in both ASD and FASD groups than the TF group. Additionally, a negative correlation between intellectual ability and TMR thresholds was observed. These preliminary results suggest intellectual ability may impact how well listeners perceive
speech in multitalker situations, especially in neurodiverse populations.

[Link to meeting program](https://acousticalsociety.org/wp-content/uploads/2022/01/Seattle_Program.pdf)
[Link to poster](Emmons_et_al_2021_ASA.pdf)

## International Society for Autism Research Annual Meeting (2021)
**Multi-Talker Speech Perception Thresholds in Young Adults with Autism Spectrum Disorder**
K. A. Emmons(1), A. M. Estes(1), S. R. Dager(2), A. K. Lee(1) and B. K. Lau(3), 
(1)Speech and Hearing Sciences, University of Washington, Seattle, WA, (2)Radiology, University of Washington, Seattle, WA, (3)Otolaryngology-Head and Neck Surgery, University of
Washington, Seattle, WA

Background: When multiple people are talking at the same time, referred to as multi-talker situations, listeners must segregate competing voices into distinct auditory streams. Acoustic cues such as pitch and loudness as well as binaural cues stemming from differences between the two ears can aid segregation. Prior research suggests neurotypical listeners can use acoustic and binaural cues to selectively attend to the desired talker even when competing voices are louder. Auditory processing differences, including difficulty listening under noisy conditions, have been reported in individuals with autism spectrum disorder (ASD). Despite these reported challenges, few studies have investigated multi-talker speech perception in individuals with ASD.

Objectives: This study investigates differences in multi-talker speech perception thresholds in young adults with ASD and age and sex-matched controls. We hypothesize that the ASD group will show greater difficulty attending to a single talker in the presence of competing talkers compared to the control group.

Methods: Twenty-four participants aged 21-23 years (n=12 ASD; n=12 Control) participated in this study. ASD participants were recruited from a larger longitudinal study conducted at the University of Washington Autism Center. All participants passed an audiometric screen (≤ 20dB hearing level at octave frequencies between 250 and 8000 Hz) to ensure clinically normal hearing thresholds. Auditory stimuli were sentences from the Coordinate Response Measure (CRM) corpus. Listeners were presented with three simultaneous CRM sentences: the target talker to be attended (0° azimuth) and two spatially separated (±45° azimuth) competing talkers. Speech perception thresholds in terms of signal-to-noise ratios (SNRs), were estimated as the level difference (dB) between the target and the two competing talkers, where a positive SNR indicated that the target talker had to be louder than the competing talkers and a negative SNR indicated that the target talker could be quieter than the competing talkers.

Results: Overall, all participants were able to perform this multi-talker speech perception task. This suggests that both ASD and control participants were able to utilize the available acoustic and binaural cues to segregate simultaneous speech streams (i.e., selectively attend to one talker when three people were talking at once). Preliminary analyses show a trend towards worse speech perception thresholds in the ASD group compared to the control group (two-tailed t-test; t=1.81, p=.08). As a group, most individuals with ASD required the target speaker to be louder than the two competing talkers (M=2.69, SD=4.15). In comparison, individuals in the control group were able to selectively attend to the target talker even when competing talkers were louder (M=−0.67, SD=4.90).

Conclusions: These results suggest young adults with ASD have the ability to use acoustic and binaural cues to listen successfully when multiple people are talking at the same time. However, as a group, adults with ASD in this sample required the person they were attending to be louder than competing voices. Understanding auditory processing differences in ASD may reveal new information about contributors to social and communication challenges. 

[Link to meeting program](https://cdn.ymaws.com/www.autism-insar.org/resource/resmgr/docs/annualmeeting/Abstract_Book_INSAR2021Virtu.pdf)
[Link to poster](Emmons_et_al_INSAR2021.pdf)

## International Society for Autism Research Annual Meeting (2020)
**Auditory Attention Switching Difficulty in Young Adults with Autism Spectrum Disorder**
Background: Communication in everyday life depends crucially on the ability to dynamically switch attention between competing auditory streams. Many of us do so effortlessly, such as switching attention between different speakers at a party. Sensory processing difficulties, particularly in the auditory domain, are commonly reported by individuals with autism spectrum disorder (ASD). Past studies have shown various auditory processing de#cits in ASD, including difficulty listening under noisy conditions and impaired cross-modal attention switching; however, few studies have looked specifically at auditory attention deployment in ASD.

Objectives: This study investigates individual differences in the ability to switch auditory attention in young adults with ASD and age- and sex-matched controls. We hypothesize that individuals with ASD will demonstrate di"culty switching auditory attention.

Methods: Twenty-two participants aged 21 to 22 years (ASD n=11; TD n=11) were recruited from a larger longitudinal study conducted at the University of Washington Autism Center. All participants passed an audiometric screen of <= 20 dB hearing level at octave frequencies between 250 and 8000 Hz for inclusion in the study. The study paradigm consisted of presenting participants with two simultaneous auditory streams, each consisting of two compound words. On Switch Attention trials, participants were instructed to attend to the #rst speaker for the #rst word, then switch attention to the second speaker for the second word. On Hold Attention trials, participants were instructed to attend to the #rst speaker for both the #rst and second words. In each trial, the speakers were either both male, both female, or a male/female pair. Speakers’ sex was manipulated to make the task harder (male/male or female/female) or easier (male/female). Additionally, speakers were either co-located (both from the left or both from the right) or spatially separated (one from the left and one from the right). There were 8 blocks, each consisting of 24 trials, for a total of 192 trials per participant. The entire task lasted approximately 30 minutes and was performed while the participant was undergoing magnetoencephalography recording.

Results: A two-way mixed ANOVA was conducted to investigate the effect of group and condition on task performance. There was a significant main effect of group, F(1,20) = 15.45, p = 0.001, with the TD group performing better than the ASD group. One-way ANOVAs were conducted to investigate the effect of group on performance and showed a TD advantage across all conditions. The ASD group performed above chance on Maintain Attention trials, and on Switch Attention trials where speakers were a male/female pair and spatially separated. However, on Switch Attention trials where speakers were male/male or female/female or where their voices were co-located, the ASD group did not perform above chance.

Conclusions: These results suggest that young adults with ASD can switch attention from one auditory stream to the other when speakers’ voices are a male/female pair and spatially separated, although less accurately than TD individuals. The ASD group showed greater difficulty switching attention from one stream to the other when speakers’ voices were both male or both female or were co-located.

[Link to poster](Emmons_et_al_INSAR2020.pdf)

